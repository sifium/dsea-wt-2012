\documentclass[a4paper,draft,twoside,10pt]{report}
\usepackage{geometry}
\usepackage[utf8x]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[german,figure,linesnumbered,lined]{algorithm2e}
\usepackage{tikz}
\usepackage{tkz-fct}
\usepackage{color}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{float}
\geometry{top=25mm, left=25mm, right=25mm, bottom=30mm}
\lstset{language=C++}
\setlength{\columnsep}{3em}

\begin{document}

\begin{titlepage}
\center
\Large DSEA WS 12-13\large \\[2em]
Dozent:\\Elmar Schömer\\[2em]
Mitschrift von:\\André Groß\\[2em]
Zuletzt Aktualisiert:\\\today\\
\includegraphics[scale=.2]{figures/uni_logo.png}\\[3em]
\Large \textbf{Zusammenfassung:}\\[1em]
\parbox{0.75\textwidth}{\large
Im Mittelpunkt der Veranstaltung stehen Methoden zur Entwicklung (vor allem \mbox{zeit-)} effizienter Algorithmen. Dabei betrachten wir insbesondere solche Datenstrukturen, die eine effiziente Verwaltung von dynamischen Datenmengen ermöglichen. Ein Teil der Algorithmen und Datenstrukturen wird in den Übungen implementiert.\\[.5em]

Mit dem Studium dynamischer Datentypen sowie weiterer Algorithmen schließt die Veranstaltung direkt an Einführung in die Programmierung bzw. Einführung in die Softwareentwicklung an. Allerdings werden nun mathematische Methoden zur Analyse von Algorithmen (Korrektheit und vor allem Aufwand) eingesetzt.\\[.5em]

http://cg.informatik.uni-mainzde/dsea\\
\textbf{Raum:} Mi C02, Mo 03-428\\
\textbf{Abgabe:} Mittwochs 12:00\\
\textbf{Sprache:} Grundsätzlich Java, ggf auch Python
}
\end{titlepage}
\normalsize
\tableofcontents
\twocolumn

\part{Skriptum}
\include{skriptum}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Die letzte(n) Vorlesung(en)}
\chapter{VL 12.11.}
\section{AVL-Bäume}
Dies sind Bbinäre Suchbäume, welche sich selbst balancieren.
\begin{figure}[H]\center
\includegraphics[trim= 1cm 25cm 13cm 1cm,clip,width=.7\columnwidth]{figures/avlbase.pdf}
\caption{AVL-Baum}
\end{figure}
\begin{figure}[H]\center
\includegraphics[trim= 1cm 22cm 10cm 6cm,clip,width=\columnwidth]{figures/avlbase.pdf}
\caption{AVL-Bäume mit Tiefe $t=2$}
\end{figure}
\begin{figure}[H]\center
\includegraphics[trim= 1cm 14.1cm 3cm 8cm,clip,width=\columnwidth]{figures/avlbase.pdf}
\caption{AVL-Bäume mit Tiefe $t=3$}
\end{figure}
\begin{figure}[H]\center
\includegraphics[trim= 1cm 11cm 16cm 15.5cm,clip,width=.6\columnwidth]{figures/avlbase.pdf}
\caption{Ein AVL-Baum mit Tiefe $t=3$ sieht niemals so aus, da er balanciert ist.}
\end{figure}
\begin{figure}[H]\center
\includegraphics[trim= 1cm 22cm 9cm 1cm,clip,width=.7\columnwidth]{figures/avlins.pdf}
\caption{Ein AVL-Baum}
\end{figure}
\begin{figure}[H]\center
\includegraphics[trim= 1cm 16cm 11cm 8cm,clip,width=.7\columnwidth]{figures/avlins.pdf}
\caption{Einfügen in A}
\end{figure}
\begin{figure}[H]\center
\includegraphics[trim= 1cm 10cm 4cm 14cm,clip,width=\columnwidth]{figures/avlins.pdf}
\caption{Einfügen in C}
\end{figure}
\chapter{VL 14.11.}

\chapter{VL 19.11.}
\section{AVL \, Bäume \, Wiederholung}

Die Logaritmische Tiefe ist wichtig für die Suchzeit usw.\\
Linker und Rechter Teilbaum dürfen sich für Suche usw. in ihrer Tiefe nur um max. Eins unterscheiden.

\begin{align*}
f(z) &=(z+c)^p \\
&=\sum_{n=0}^\infty \frac{1}{n!}f^{(n)}(z0)(z-z_0)\\
\mbox{wähle }&z0=0\\
f'(z)&=p(z+c)^{p-1}\\
f''(z)&=p(p-1)(z+c)^{p-2}\\
f^{(n)}(z)&=p(p-1)(p-2)\hdots(p-n+1)(z+c)^{p-n}\mbox{(Taylor)}\\
\mbox{hier fehlt was!}
\end{align*}

\begin{align*}
b_0=1,b_n&=\sum_{i=1}^nb_{i-1}b_{n-i}\\
B(z)&=\sum_{n=0}^\infty b_nz^n\Rightarrow B(z)\frac{1-\sqrt{1-4z}}{2z}\\
\sqrt{1-4z}&=(1-4z)^\frac{1}{2}\\
&=\sum_{n=0}^\infty \left(\begin{array}{c}\frac{1}{2}\\n\end{array}\right)1^{\frac{1}{2}-n}(-4z)^n\\
&=\sum_{n=0}^\infty\begin{array}{c}\frac{1}{2}\\n\end{array}(-4)^nz^n\\
&=1+\sum_{n=0}^\infty \begin{array}{c}\frac{1}{2}\\n\end{array}(-4)^nz^n\\
&=1+\sum_{n=0}^\infty \begin{array}{c}\frac{1}{2}\\n+1\end{array}(-4)^{n+1}z^{n+1}
\end{align*}

hier fehlt auch noch ne Menge...
\[b_n=-\frac{1}{2}\begin{array}{c} \frac{1}{2} \\n+1\end{array}(-4)^{n+1}\]
den rest kann ich nicht lesen....

\section{Bijektion zwischen Binär\-bäumen}
\[n=3; c_c=\frac{1}{n+1}\begin{array}{c} 2n\\n\end{array}\Rightarrow c_3=5\]
Graphik

\section{Amortisierte Analyse am Beispiel von 2-5-Bäumen}
a-b-Bäume: Jeder Knoten Des Baumes hat mind a Kinder und Höchstens b Kinder.
Blattorientierte Speicherung der zu verwaltenden Elemente
\begin{figure}[H]\center
\includegraphics[trim= 1.8cm 20cm 2cm 1.3cm,clip,width=\columnwidth]{figures/aa25baum.pdf}
\caption{2-5-Baum}
\end{figure}
Zahl der Blätter n :
\[2^t\le n\le 5^t\]
\[\log_5n \le t\le  \log_2n\]
\[\Rightarrow t\in \theta (\log n)\]

Strategie zum Einfügen und Löschen von Elementen

\begin{figure}[H]
\includegraphics[trim= 1cm 20cm 1cm 1cm,clip,width=\columnwidth]{figures/25bauminsert.pdf}
\caption{Einfügen in 2-5-Baum}
\end{figure}

Beim Löschen von Elementen kann eine Kaskade Von Fusionsoperatoren auf dem Suchpfad notwendig werden. Ggf. Wurzel löschen und Kinder Zusammenlegen.

Laufzeit für Suchen, Einfügen, Löschen $\in \theta(\log n)$

\chapter{VL 21.11}
\section{Amortisierte Analyse am Beispiel des Binärzählers}

\begin{figure}[H]\center
\includegraphics[trim= 1cm 18cm 15cm 1cm,clip,width=0.4\columnwidth]{figures/zaehler.pdf}
\caption{Binärzähler}
\end{figure}

Worst case Kosten einer Inkrement- Operation $$\mathcal O(\log_2n)$$\\
Gesamtkosten für eine Folge von n Inkrement- Operationen (beginnend beim Zählerstand 0)
\begin{align*}
&\frac{n}{2}&\mbox{verursachen Kosten }&1&\mbox{Endung }&0\\
&\frac{n}{4}&\mbox{verursachen Kosten }&2&\mbox{Endung }&01\\
&\frac{n}{8}&\mbox{verursachen Kosten }&3&\mbox{Endung }&011\\
&\frac{n}{16}&\mbox{verursachen Kosten }&4&\mbox{Endung }&0111\\
\end{align*}

Gesamtkosten:\\
\[\le \sum_{i=1}^\infty i\frac{n}{2^i}=n\sum_{i=1}^\infty i\left(\frac{1}{2}\right)^i =2n\]

\fbox{\parbox{\columnwidth}{ Nebenrechnung:\small
\begin{align*}
x\sum_{i=1}^\infty ix^{i-1}&=x\left(\sum_{i=0}^\infty x^i\right)'\\
&=x\left(\frac{1}{1-x}\right)'\\
&=\frac{x}{(1-x)^2}
\end{align*}
}}

\subsection{Kontomethode}
\begin{align*}
Konto(i)&= \mbox{Kontostand vor der i-ten Operation}\\
cost(i)&=\mbox{tatsächliche Kosten der i-ten Operation}\\
\sum_{i=1}^n cost(i)&=\sum_{i=1}^n Konto(i)-Konto(i+1)+a(i)\\
a(i)&=\mbox{ammotisierte Kostender i-ten Operation}\\
\Rightarrow \sum_{i=1}^n cost(i)&=Konto(i)-Konto(n+1)+\sum_{i=1}^n a(i)
\end{align*}

\subsection{amortisierte Analyse der Rekonstruierungskosten für eine Folge von m Einfüge- oder Löschoperationen in einem 2-5-Baum}
Ausgangspunkt: leerer Baum\\
Nicht betrachtet werden die Suchkosten. Wir konzentrieren uns auf die Split- und Fusions-Operationen.\\[.5em]
Kontoführung:\\
\begin{tabular}{rcccccc}
Knotengrad&1&2&3&4&5&6\\
Sparbetrag&2&1&0&0&1&2
\end{tabular}\\[.5em]
Sparplan:\\
$2RE$ pro Einfüge- bzw.Löschoperation\\
$a_i=2$\\
\textbf{Einfügen:}
\begin{figure}[H]\center
\includegraphics[trim= 6cm 24cm 6cm 1cm,clip,width=.9\columnwidth]{figures/zaehler.pdf}
\caption{Kosten 2-5-Baum einfügen}
\end{figure}
\textbf{Löschen:}
\begin{figure}[H]\center
\includegraphics[trim=  6cm 18.5cm 6cm 7cm,clip,width=.8\columnwidth]{figures/zaehler.pdf}
\caption{Kosten 2-5-Baum Löschen}
\end{figure}

Die m Einfüge- und Löschoperationen auf einem anfangs leeren Baum haben amotisierte Kosten=2.
$\Rightarrow$ Rekonstruierungskosten insgesamt belaufen sich auf $2m$

\chapter{VL 26.11.}
\subsection{Skiplisten}
\begin{figure}[H]
\begin{verbatim}
class ListNode{
   int kex;
   ListNode next,down;

   boolean search(int x){
      ListNode node = head;
      do{
          while(x>node.next.key)
            node=node.next;
         if (x == node.next.key)
            return true;
         node = node.down; 
      }while(node!=null)
      return false;
      }
}
\end{verbatim}
\caption{Skiplisten Pseudocode}
\end{figure}

\begin{figure}[H]\center
\includegraphics[trim= .9cm 22cm .9cm 1cm,clip,width=\columnwidth]{figures/skiplist.pdf}
\caption{Skipliste, ein Beispiel}
\end{figure}

\begin{figure}[H]\center
\includegraphics[trim= .9cm 14cm .9cm 8cm,clip,width=\columnwidth]{figures/skiplist.pdf}
\caption{In Skipliste einfügen}
\end{figure}

Erwartete Tiefe:\\
mit Wahrscheinlichkeit $p$ soll ein Element von Level $i$ auf Level $i+1$ angehoben werden\\
Erwartete Zahl von Elementen auf Level $i$: \, $p^in$
\[p^in<1 \Rightarrow n < \left(\frac{1}{p}\right)^i \Rightarrow i>\log_\frac{1}{p}n\]

Suchzeit:\\
Wir müssen die Ebenen von oben nach unten durchlaufen.\\
Die Frage ist, wie viele Elemente bei der verfeinerten Liste hinzukommen.\\
\begin{figure}[H]\center
\includegraphics[trim= .9cm 9cm 8.9cm 18cm,clip,width=.8\columnwidth]{figures/skiplist.pdf}
\caption{In Skipliste einfügen}
\end{figure}
\begin{align*}\mathcal X = &\mbox{Zahl der Elemente auf Level i zwischen zwei}\\&\mbox{benachbarten Elementen auf Level i+1}\end{align*}
\[E(\mathcal X)=\sum_{j=1}^\infty j(1-p)^{j-1}p=p\frac{1}{(1-(1-p))^2}=\frac{1}{p}\]
Erwartete Suchzeit:
\[T_P(n)=\frac{1}{p}\log_\frac{1}{P}n=\mathcal O (\log n)\]
plot $\frac{x}{ln x}$ mit hervorheben des Sattelpunktes
\begin{align*}
f(x)&=x\log_xn\\
&=\frac{x\ln n}{\ln x}\\
f'(x)&=\ln n \frac{1\ln x -x\frac{1}{x}}{(\ln x)^2}=0\\
&\Rightarrow \ln x = 1\\
&\Rightarrow x=e \\
&\Rightarrow p=\frac{1}{e}
\end{align*}

\subsection{Dynamisches Programmieren}
es ist eine Technik um sich optimale Lösungen für Teilprobleme zu suchen.\\
\textbf{Beispiel:}\\
Sie sollen eine reihe von Matrizen multiplizieren. Die Dimensionen der Matrizen können durchaus unterschiedlich sein, was ist nun eine geschickte Reihenfolge um möglichst wenig Operationen zu benötigen?\\
geg: $n$-Matrizen $A_i$ für $i=1,\hdots,n$ , $A_i\in\mathbb R^{d_i\times d_{i+1}}$\\
ges: Optimale Auswerte-Reihenfolge für das Produkt $A_1 \dot A_2 \dot A_3 \dot \hdots \dot A_n$\\
Beispiel: $n=3$\\
\begin{align*}
(A_1 A_2) A_3 &= 2 10 5 + 2 5 8 &=180\\
A_1 (A_2 A_3) &= 10 5 8 + 2 10 8&= 560
\end{align*}

\[cost(A_i A_{i+1})=\theta(d_i d_{i+1} d_{i+2})\]
Bild 2\\
\[(A_1\hdots A_k)(A_{k+1}\hdots A_n)\]
\textbf{Idee:} Suche nach optimaler Teillösung und Konstruiere daraus die optimale Gesamtlösung.\\
\[cos(A_i A_{i+1} \hdots A_j)=c_{ij}\]
\[c_{ij}=\min_{i<k<j}c_{ik}+c_{k+1,j}+d_{i}d_{k+i}d_{j+1}\]
\chapter{VL 28.11}
Andere Schreibweise:
\[c_{ij}=cost(A_i A_{i+1} \hdots A_j)\]
\[c_{ij}=\min_{k=1,\hdots j-1}(c_{ik}+_{i+k,j-k}+d_id_{i+k}d_{i+j})\]
\begin{figure}[H]\center
\includegraphics[trim= 3cm 16cm 7cm 2cm,clip,width=.7\columnwidth]{figures/skyscraper.pdf}
\caption{ka was das sein sollte :)}
\end{figure}

\subsection{Egg Dropping}
\begin{align*}&n=15[\mbox{Stockwerke}]&\,&\,&k=2[\mbox{Eier}]&
\end{align*}
\begin{figure}[H]\center
\includegraphics[trim= 2cm 1.5cm 7.5cm 16cm,clip,width=\columnwidth]{figures/skyscraper.pdf}
\caption{Egg dropping von einem 15 stöckigen Hochhaus}
\end{figure}
Die Zahl der verbleibenden Versuche bei $n$ verbleibenden Stockwerken und $k$ verbleibenden Eier bezeichnen wir als $t_{n,k}$.
Betrachten wir nun den Wurf eines der k Eier aus Stockwerk x und die beiden möglichen Ergebnisse.
\[t_{n,k}=1+\min_{2\le x\le n}\max(t_{x-1,k-1},t_{n-x,k})\]
\begin{description}
\item[1. Fall: ] Ei zerbricht\[t_{x-1,k-1}\]
\item[2. Fall: ] Ei überlebt\[t_{n-x,k}\]
\end{description}
\[t_{15,2}=1+\min(\max(t_{1,1},t_{13,2}),\max(t_{2,1},t_{12,2},\hdots)\]



\chapter{VL 3.12.}




\chapter{VL 5.12.}
Informationstheoretische untere Schranke für vergleichsbasierte Sortierverfahren\\
\[a[0],a[1],a[2]\]
Entscheidungsbaum:
\begin{figure}[H]\center
\includegraphics[trim= .9cm 20cm .9cm .9cm,clip,width=\columnwidth]{figures/vergleichsbaum.pdf}
\caption{Vergleichsbaum}
\end{figure}
\[a_i\ne a_j \mbox{ für }0\le i\ne j<n\]
\#Blätter im entscheidungsbaum\[\ge n!\]
Sei $t_{\max} $ die maximale Tiefe im Entscheidungsbaum
\[\Rightarrow 2^{t_{\max}}\ge n! \Rightarrow t_{\max} \ge \log_2n!\]
\[\ln n! = \ln (1\,\]

\begin{figure}[H]\center
\includegraphics[width=\columnwidth]{figures/m1.jpg}
\end{figure}

Sei $t'$ die mittlere Tiefe der Blätter im Entscheidungsbaum
\begin{figure}[H]\center
\includegraphics[trim= .9cm 15cm 14.7cm 10cm,clip,width=.4\columnwidth]{figures/vergleichsbaum.pdf}
\caption{Entscheidungsbaum}
\end{figure}
\begin{align*}
mt'(m)&=l(t'(l)+1)+r(t'(r)+1)\\
t'(m)&=\frac{l}{m}t'(l)+\frac{r}{m}+1 \mbox{ wird minimal für } l=r=\frac{m}{2}\\
t'(m)&\ge t'(\frac{m}{2})+1 \Rightarrow t'(m)\ge\log_2m\end{align*}

\section{Hashing mit Verkettung}
BILD\\
Verwaltung einer unsortierten Menge.
\begin{itemize}
\item search
\item insert
\item delete
\end{itemize}
\[|U|>>m~n=\#\mbox{verwaltete Elemente}\]
\[h:U\rightarrow\{0,1,\hdots,m-1\}\mbox{ Hashfunktion}\]
Belegungsfaktor der Hashtabelle
\[\alpha =\frac{n}{m}\]
Idealisierte Annahme:\\
Hashfunktion $h$ verteilt die n Elemente zufällig gleichverteilt auf die m Tabelleneinträge.

$n_i$ sei die erwartete Anzahl von Elementen, die auf Tabelleneintrag $i$ gehasht werden.
\[n_i=\alpha =\frac{n}{m}\Rightarrow \mbox{ Suchzeit }=\mathcal O(1+\alpha)\]
unter der Vorraussetzung, dass sich die Hashfunktion in Konstanter Zeit auswerten lässt.\\
Beispiel der Wahl einer Hashfunktion:
\[h(k)=(ak+b)\mod m\]


\chapter{VL 10.12.}
Idealisierte Annahme:
Die n Elemente werden unabhängig und gleichverteilt auf die m Tabellenplätze abgebildet.
\[h: U\rightarrow \{0, \hdots, m-1\}\]

\textbf{Frage:} Wie hoch ist die mittlere Suchzeit für ein zufälliges Element aus der Tabelle?
Sei $k_1,k_2,\hdots , k_n$ die Einfügereihenfolge der $n$ Schlüssel in die Tabelle?
\begin{align*}
\mathcal X 
\end{align*}

%\begin{figure}[H]\center
%\includegraphics[width=\columnwidth]{figures/m2.jpg}
%\capture{Nachtrag}
%\end{figure}

\section{Universelles Hashing}
$\mathcal H$ Klasse von Hashfunktionen
z.B. $h(k) = (ak+b) \mod p \mod m $
$1\le a < p, 0\le b < p \, m<p \mbox{Primzahl}$

\textbf{Def.} $\mathcal H$ heißt universell
\[\Leftrightarrow \forall k \ne l \in U : | \{h\in \mathcal H | h (k) = k(l) \} |\le \frac{|\mathcal H|}{m}\]

Sei $n_i$ die erwartete Länge der Kollisionsliste bei Feldeintrag $i$.
\[y_k = \mbox{Länge der Kollisionsliste für den Schlüssel $k$}\]

\chapter{VL 12.12.}
\begin{align*}E(\sum_{i=0}^{n-1}n^2_i)=E(\sum_{i=0}^{n-1}(n_i+2(\begin{array}{c}n_i\\2\end{array})))=E(\sum_{i=0}^{n-1}n_i)+2E(\sum_{i=0}^{n-1}(\begin{array}{c}n_i\\2\end{array}))\end{align*}
Dies entspricht der Zahl der Kollidierendden Paare in dar Primärtabelle.
\[=n+2E(\sum_{k\ne l\in T} \mathcal X_{kl})=n+2\sum_{k\ne l\in T} E(\mathcal X_{kl})\]
\[=n+2(\begin{array}{c}n\\2\end{array})\frac{1}{n}=n+\frac{2n(n-1)}{2n}\le 2n\]
Weitere Klasse von univversellen Hashfunktionen
\[E(a\mathcal X+ b\mathcal Y) =aE(\mathcal X)+bE(\mathcal Y)\]
\[k=(k_1,k_2,\hdots, k_d) ,0\le k_i <p\]\[a=(a_1, \hdots,a_d)\]
\[h_a(k)=\sum_{i=1}^d a_ik_i \mod p\]
 Tabellengröße $m=p$ Primzahl.
\[\mathcal H=\{h_a|a=(a_1,\hdots ,a_d), 1\le a_i<p\}\]
\[\mathcal H =(p-1)^d\]
Wähle $k\ne l$
\[h_a(k)=\sum_{i=1}^d a_i k_i \mod p =\sum_{i=1}^d a_i l_i \mod p =h_a(l)\]

FEHLEND

Für jede der $(p-1)^{d-1}$ Möglichkeiten die $a_i$'s auf der rechten Seite zu wählen gibt es genau ein $a_j$, das zu einer Kollission zwischen den Schlüsseln $k$ und $l$ führt.


\section{Graphen}
Ein Graph $G$ besteht in der Regel aus Vertices $V$ und Kanten (Edges) $E$.
\[G=(V,E)\]
\[E\subseteq V\times V\]
$(u,v)\in E$ gerichtet\\
$\{u,v\}$ ungerichtet\\
DAG : directed acyclicgraph\\
planare Graphen\\
Eulersche Polyederformel
\[|V|+|F|=|E|+2\]
Würfel: $8+6=12+2$\\

\subsection{Adjazenzmatrix $A$}
\[A_{u,v} = \left\{\begin{array}{ll}1&\mbox{falls $(u,v)\in E$}\\0&\mbox{sonst}\end{array}\right.\]
Speicherbedarf: $\mathcal O(|V|^2)$\\
 
Adjazenzliste\\
FIGURE\\

\section{Tiefensuche}
\textbf{engl.} Depth-First-Search
\begin{figure}[H]
\begin{verbatim}
forall v in V
   visited [v] =false;
stack S;
S.push(s); // s entspricht Startknoten
while(!S.empty()) {
   u=S.pop();
   forall(u,v) in E
      if(!visited[v]){
         S.push(v);
      }
}
visited[v]=true;
\end{verbatim}
\caption{Pseudocode Tiefensuche}
\end{figure}

\chapter{VL 17.12.}
\section{Breitensuche}
Fehlend
\section{Kürzeste Wege Algorithmen.}
Eigenschaften von Algorithmen , die mittels Kantenrelaxierungen kürzeste Wege bestimmen.

Obere Schranke: $\forall v\in V : d[v] \ge S(s,v)$
Beweis durch Induktion nach der Zahl der Kantenrelaxierungen.
\begin{description}
\item[IA] Nach initialisierung gilt die Induktions-Annahme.
\item[IS] $relax(u,v)$
\begin{description}
\item[1.Fall] $d[v]$ wird nicht verändert, woraus die Richtigkeit der IA folgt.
\item[2.Fall] ...
\end{description}
\end{description}

Konvergenzeigenschaft:\\
Sei $s \rightsquigarrow u\rightarrow v$ein Kürzester Weg von $s$ nach $V$ mit $d[u]=S(s,u)$, denn gilt nach dem Relaxieren der Kante $(u,v):d[v]=S(s,l)$
\[d[v]\le d[u]+w(u,v)=S(s,u-+w(u,v)=S(s,v)\]

Korrektheitsbeweis Bellman-Ford\\
Betrachte einen kürzesten Weg $s=v_0\rightarrow v_1 \rightarrow \hdots \rightarrow v_k=v$
Folgende Invariante gilt: Nach dem $i$-ten Schleifendurchlauf: $d[v_i=S(s,v_i)$
Ind. Bew. 
$s \rightsquigarrow v_i \rightarrow v_{i+1}$
Im $(i+1)$-ten Schleifendurchlauf wird irgendwann auch die Kante $(v_i,v_{i+1})$ relaxiert.
Konvergenzeigenschaft: $d[v_{i+1}]=S(s,v_{i+1})$

Erkennung negativer Zyklen
\begin{verbatim}
forall (u,v) in E
   if (d[v] > d[u] +w(u,v))
      return negativer Zyklus erkannt
return kein negativer Zyklus vorhanden
\end{verbatim}
Sei $c = (s=v_0\rightarrow v_1 \rightarrow \hdots \rightarrow v_k=v)$ ein negativer Zyklus $\sum_{i=1}^k w(v_{i-1}, v_i)<0$

\chapter{VL 19.12.}
\section{Dijkstra-Algorithmus}
\[G=(V,E)\, w:E\rightarrow \mathbb R^+\]

\begin{verbatim}
init();
PriorityQueue Q = V;
S = \emptyset
while(!Q.empty()){
   u=Q.deletemin();
   S = Sv{u}; 
   relax(u,v){
      if(d[v]>d[u]+w(u,v)){
         d[v]=d[u]+w(u,v);
         pred[v]=u;
         Q.decreasekey(v);
      }
      forall (u,v) \in E
         relax(u,v);
   }
\end{verbatim}
\textbf{Laufzeit:}\\
\[\mathcal O(|v|cost(deletemie)+|E|cost(decreasekey))\]
\[\mathcal O((|v|+|E|)\log |v|)\]
wenn PriorityQueue durch balancierten Suchbaum verwaltet wird.\\[.5em]
alternativ $\mathcal O (|v|\log |v|+|E|)$ PQ mit Hilfe von Fibonacci-Heaps

\subsection{Korrektheitsbeweis}
BILD\\
\begin{description}
\item[Beh.]$\forall v \in V$ gilt nach Ablauf des Algorithmus $d[v]= S(s,v)$
\item[Bew.] durch Widerspruch\\
Annahme $\exists v:d[v]> S(s,v)$ (obere Schrankeneigenschaft)\\
Sei $v$ der erste Knoten, für den dies gilt, zum Zeitpunkt, wenn er aus $Q$ entnommen wird.\\
Sei $s \rightsquigarrow x\rightarrow y \rightsquigarrow v$ ein kürzester Weg von $s$ nach $v$.
\[d[v]\le d[y]=S(s,y)\le S(s,v)<d[v]\]
$\le $ gilt aufgrund der positiven Kantengewichte.\\[.5em]
$d[x]=S(s,x)$ weil $x$ vor dem "falschen" Knoten $v$ betrachtet wird.\\[.5em]
Konvergenzeigenschaft $d[y]=S(s,y)$ weil $x\rightarrow y$ relaxiert und $s \rightsquigarrow x\rightarrow y $ kürzester Pfad.\\[.5em]
$d[v]\le d[y]$, $v$ wird vor $y$ aus der PQ entnommen.
\end{description}


\chapter{VL 07.01.}
\chapter{VL 09.01.}


\chapter{VL 14.01.}
\begin{verbatim}
FibNode{
   Fibnode left, right, down, up;
   int deg;
   bool mark;
   float key;
}

FibHeap{
   Fibnode min;
   ... decreaseked, deletemin,
         consolidate, insert;
}

void decreasekey (Fibnode x, float newkey){
   if(newhey>x.key error;
   x.key=newkey;
   if(x.up ==null){
      if(x.key<minkey) min=x;
      return;
   }
   FibNode y=x.up;
   if(x.key >= y.key) return;
      //löse x ab
   do{ y=x.up;
      remove x from y childlist;
      y.degree--;
      add x to rootlist;
      x.up F null;
      x.mark = false;
      if (x.key <min.key) min = x;
      x=y;
   } while (x.mark== true);
}

void consolidate(){
   int dmax =floor(log(phi,n));
   Fibnode[] A=new FibNode(dmax+1);
   for(int i=0;i<=dmax;i++){
      FibNode x=v;
      int d =x.deg;
      while (A[d]!=Null){
         FibNode y=A[d];
         if(x.key>y.key)
            swap(x,y);
         remove y from rootlist;
         add y to childlist of x; x.deg++;
         d++;
      }
      A[d]=x;
   }
   for(int i=0;i<=dmax;i++)
      if (A[i]!= Null){
         add A[i] to new rootlist;
         if (A[i].key<min.key) min =A[i];
      }
}
\end{verbatim}

\section{Minimal aufspannende Bäume}
$G=(V,E)$ zusammenhängend, ungerichtet. 

Mit einer Kostenfunktion $ w: E\rightarrow \mathbb R$

Gesucht ist ein \textbf{Spannbaum} $T_{min} \subseteq E$ mit
\[w(T_{min})=\sum _{(u,v)\in T_{min}} w(u,v) \mbox{minimal}\]
\begin{verbatim}
Greedy-Algo
T= emptyset;
while (T noch kein Spannbaum){
   wähle eine sichere Kante (u,v) in E
   T=T cup {(u,v)};
}
\end{verbatim}
\subsection{Lemma}
Sei $T_{min}$ ein minimaler Spannbaum für $G=(V,E)$
bzgl. $w: E\rightarrow \mathbb R $ und $ T\subseteq T_{min} \subseteq E$ eine Teillösung.

Sei $(S,V\/S) $ ein Schnitt von $G$ und die Kanten von $T$ respektieren diesen Schnitt $\nexists (u,v)\in T, u\in S, v\in V\/ S)$
dann ist die Kante $(u,v)$ mit minimalem Gewicht, die den Schnitt kreuzt, eine sichere Kante für $T$.

Somit $T' = T \cup \{(u,v)\}$ und $T' $ zu $T_{min}$ ergänzt werden kann.

\subsection{Beweis}
Sei $T_{min}$ ein minimal aufspannender Baum, der aus der Teillösung $T$ entstanden ist.

\chapter{VL 16.01.}
Sei $(u,v)\in E$ die Kante mit kleinstem Gewicht, die über den Schnitt führt.
\begin{align}
&T_{min}\\
&T\\
&T\cup T_{min}
\end{align}
Der gewählte Schnitt $(S,V\/S)$ \textbf{respektiert} die Teillösung $T$, d.h. keine Kante von $T$ läuft über diesen Schnit
\[T' =T\cup \{(u,v)\}\]
$T' $ kann zu einem minimalen Spannbaum $T'_{min} $ ausgebaut werden.
\[w(T'_{min}= w(T_{min}\]
Durch Einfügen von $(u,v)$ in $T_{min}$ entsteht ein Zyklus $C$.
Da $u\in S$ und $v\in V\/S$ gibt es miedestens eine Kante von $C\/\{(u,v)\}$ die über den Schnitt führt: $w(x,y) \geq w(u,v)$
\[T'_{min}=T_{min}\/ \{(x,y)\}\cup \{(u,v)\}\]
$T'_{min}$ ist ebenfalls Spannbaum.
\[w(T_{min})\leq w (T'_{min})Fw(T_{min})-w(x,y)+w(u,v)\leq W(T_{min})\] 
\textbf{BILD}
\begin{table}[H]
\begin{tabular}{ccccccccc}
$v$&1&2&3&$\hdots$&7&$\hdots$&12&13\\\hline
$rep$&1&2&3&$\hdots$&1&$\hdots$&12&13\\
$next$&7&-1&-1&$\hdots$&-1&$\hdots$&12&13\\
\end{tabular}
\end{table}
$rep$ ist der Repräsentanten-Knoten zur Identifikation einer Komponente.

Die Korrektheit folgt unmittelbar aus dem Cut-Lemma.

\subsection{Laufzeit}
Sortierphase 
\[\mathcal O(|E|\log |V|)\]

mit
\[|E|\leq |V|^2 \,\,,\,\, \log|E|=\mathcal O (\log |V|)\]

Baumphase
\[|E| * find-Op\]
\[|V| * union-Op\]

\section{Bemerkungen zu den Kosten der Union-find-Operationen}
Beim Kruskal-Algorithmus:
\[cost(find)= \mathcal O(1) \mbox{, da nur 2 Feldzugriffe nötig}\]
\[\sum^{|V|-1}_{i=1}cost(union_i)=\mathcal O(|V|\log |V|)\]
Voraussetzung: Repräsentanten der jeweilskürzeren Liste werden umbenannt.

Frage aus der Sicht eines Knotens:
"Wie oft werde ich umbenannt?"

Antwort: Nach jeder Umbenennung verdoppelt sich die Komponentengröße mindestens.
\[ \mbox{nach }k\mbox{-Umbenennungen}\le 2^k \Rightarrow k\le \log_2 |V|\]
Gesamtlaufzeit
\[\mathcal O(|E|\log|V|+|E|+|V|\log|V|)=\mathcal O(|E|\log|V|)\]
Geht es schneller?



\chapter{VL 21.01.}
\section{Prim-Algorithmus}

BILD

Distanzfeld $d$ verwaltet die minimale Entfernung des Knotens zu den Knoten $S$ der Teillösung $T$.

\begin{verbatim}
if(w(v,v_1)<d[v_1]){
   d[v_1]=w(v,v_1);
   pi[v_1]=v;
}

forall v\in V{
   d[v]= \infty ;
   pi[v]=-1;
}
d[s]=0;
T=\emptyset ;
PriorityQueue Q(V,d);
while (!Q.empty(){
   v=Q.deletemin();
   if(v \neq s)
      T=T \cup {(pi(v),v)};
   forall (v' \in Adj(v) && v' \in Q)
      if(w(v,v')<d[v]){
         d[v']=w(v,v');
         pi[v']=v;
   }
}
\end{verbatim}
Nach Ablauf des Prim-Algo. gilt:
\[T_{min}=\{(\pi(v),v)|v\in V\/\{s\}\}\]
Laufzeit:
\[\mathcal O(|V|cost(deletemin)+|E|cost(decreasekey))\]
\[= \mathcal O (|V|\log|V|+|E|)\]
\section{Flussalgorithmen}
\[G=(V,E)\,\,\,\mbox{gerichtet.}\]

mit zwei ausgezeichneten Knoten $s$ und $t$.

Gesucht ist ein maximaler Fluss
\[f:E\rightarrow \mathbb R^{>0}\]
sodass
\[0\le f(u,v)\le c(u,v)\]
Kapazitätsfunktion:
\[c:E\rightarrow \mathbb R^{>0}\]
Flusserhaltung:
\[\sum_{u\in V}f(u,v) = \sum_{u\in V} f(v,u')\]
für alle $v\in V\/\{s,t\}$\\
$|f|=$ Wert des Flusses, der von $s$ nach $t$ transportiert werden kann.

Nettofluss:
\[|f|=\sum_{v\in V}f(s,v) -\sum_{v\in V} f(v,s) \]

Ziel: Finde eine Belegung der Kanten mit Flusswerten $f$, so dass $|f|$ maximal und $f$ erfüllt Kapazitätsbedingung und Flusserhaltung.
Es gilt:
\[|f|=\sum_{v\in V} f(v,t) - \sum_{v\in V} f(t,v)\]

\subsection{Restgraph}
BILD!!!

\textit{Idee:} Finde einen Fluss $f'$ im Restnetzwerk $G_f=(V,E_f)$ und verbessere den Ausgangsfluss $f$ im Originalgraph durch Addition von $f$ und $f':f\oplus f'$




\chapter{VL 20.01.}
Restnetzwerk
\[G_f=(V,E_f)\]
\[c_f(u,v)=\left\{\begin{array}{ll}
c(u,v)-f(u,v)&\mbox{für } (u,v)\in E\\
f(v,u)&\mbox{für } (v,u)\in E\\
0&\mbox{sonst}
\end{array}\right.\]

\begin{description}
\item[1. Idee] Suche einen Fluss verbessernden Pfad $p$ im Restnetzwerk $G_f$\\
Bottleneck-Kante:\[c_f(p)=\min\{c_f(u,v) \mbox{für} (u,v)\in p\}\]
\end{description}

Sei $f$ ein Fluss im Originalgraphen $G$ und $f'$ im Restnetzwerk $G_f$, dann ist auch 

$(f\oplus f')(u,v)=\left\{\begin{array}{ll}
f(u,v)+f'(u,v)-f'(v,u)&\mbox{für } (u,v)\in E\\
0&\mbox{sonst}
\end{array}
\right.$
\begin{itemize}
\item[$(1)$]\begin{align*}(f\oplus f')(u,v)&=f(u,v)+f'(u,v)-f'(v,u)\\ &\le f(u,v)+f'(u,v)-f(u,v)\\ &=f'(u,v)\ge 0\end{align*}
\item[$(2)$]\begin{align*}(f\oplus f')(u,v)&=f(u,v)+f'(u,v)-f'(v,u)\\ &\le f(u,v)+f'(u,v)\\ &\le f(u,v)+c(u,v)-f(u,v)\\&=c(u,v)\end{align*}
\item[$(3)$]\begin{align*}\sum_{v\in V}(f\oplus f')(u,v)&=\sum_{v\in V}\{f(u,v)+f'(u,v)-f'(v,u)\}\\
&=\sum f(u,v)+\sum f'(u,v)-\sum f'(v,u)\\
&=\sum f(v,u)+\sum f'(v,u) -\sum f'(u,v)\\
&=\sum_{v\in V}(f\oplus f')(v,u)\end{align*}
\end{itemize}

\begin{align*}
|(f\oplus f')|&= |f|+|f'|\\
&=\sum (f\oplus f')(s,v)-\sum (f\oplus f')(v,s)\\
&=\sum f(s,v)+f'(s,v)-f'(v,s)-\sum f(v,s)+f'(v,s)-f'(s,v)\\
&=\sum f(s,v)-\sum f(v,s)+...?\\
&=|f|+...
\end{align*}

\section{Schnitte}
Sei $V=S\sqcup T$ mit $s\in S$ und $T\in T$ ein Schnitt durch $G$.
\[c(S,T)= \sum_{u\in S}\sum_{v\in T}c(u,v)\]

Definition:
\[f(S,T)= \sum_{u\in S}\sum_{v\in T}f(u,v)- \sum_{u\in T}\sum_{v\in S}f(u,v)\]
Es gilt:\[f(S,T)\le  \sum_{u\in S}\sum_{v\in T}f(u,v)\le  \sum_{u\in S}\sum_{v\in T}c(u,v)\le c(S,T)\]

Lemma:

Sei $f$ ein Fluss und $(S,T)$ ein beliebiger Schnitt, dann gilt:
\[|f|\le c(S,T)\]

\begin{align*}
|f|&= \sum_v f(s,v)-\sum_v f(v,s)=^! f(S,T)\\
&=\sum_v f(s,v)-\sum_v f(v,s) + \sum_{v\in V}\sum_{u\in S\/\{s\}}f(u,v)-\sum_{u\in S\/\{s\}} f(v,u)\\
&=\sum_{v\in V}\sum_{u\in S}f(u,v)-\sum_{v\in V}\sum_{u\in S}f(v,u)\\
&=.....
\end{align*}

\chapter{VL 28.01.}

\section{Max-Flow-Min-Cut Theorem}
Gegeben sei ein Fluss $f$ im Netzwerk $G=(V,E)$ von $s$ nach $t$.

Folgende Aussagen sind äquivalent:
\begin{enumerate}
\item $f$ ist ein maximaler Fluss
\item Es gibt keinen flussverbessernden Pfad im Restnetzwerk $G_f=(V,E_f)$
\item Es gibt einen Schnitt $(S,T)$ mit $|f|=c(S,T)$
\end{enumerate}
\textbf{Beweis:} $(1)\Rightarrow (2)\Rightarrow(3)\Rightarrow(1)$

Mit Kontraposition:\\
$\neg (2)\Rightarrow \neg (1)$

Sei $f'$ ein Fluss im $G_f$ entlang des existierenden flussverbessernden Pfades
\[|(f\oplus f')|=|f|+|f'| > |f|\Rightarrow f \mbox{ nicht maximal}\]

$(2)\Rightarrow (3)$
Definiere $S=\{v\in V | \exists s \rightsquigarrow v \mbox{ in } G_f\},T=V\/S, t\notin S$ da kein flussverb. von $s$ nach $t$ in $G_f$ nach Vor.

Sei $(u,v)$ mit $u\in S$ und $v\in T$, dann gilt: $f(u,v) =c(u,v)$

\textbf{Annahme:} $f(u,v)<c(u,v)\Rightarrow (u,v) \in E_f$ mit $c_f(u,v)>0 \Rightarrow s\rightsquigarrow u\rightarrow v$ in $G_f$ Blitz $v\in T$

Sei $(u,v)$ mit $u\in T$ und $v \in S$, dann gilt: $f(u,v)>0$
$f(u,v)>0 \Rightarrow (v,u) \in E_f$ mit $c_f (v,u) =f(u,v)>0$
$\Rightarrow S\rightsquigarrow v\rightarrow u$ in $G_f$ Blitz $u\in T$

\subsection{Laufzeit FF-Algo}
Ann. $c(u,v)\in \mathbb N \forall (u,v)\in E$
\[C=\sum_{v\in V} c(s,v)\in \mathbb N \]
Zahl der Iterationen $\leq C$

Laufzeit $\mathcal O(C|E|)$


































































\end{document}